# 消息队列

## Kafka 基础知识

[Kafka【入门】就这一篇！ - 知乎](https://zhuanlan.zhihu.com/p/74063251)

### 1. Kafka 简介
Apache Kafka 是一个分布式流处理平台，主要用于以下三类任务：
- **消息队列**：作为高吞吐、低延迟的消息队列，Kafka 能够可靠地传递消息。
- **日志收集**：Kafka 可以用于日志和事件数据的收集和存储。
- **流式处理**：支持实时数据流处理。

Kafka 的特点：
- 高吞吐量：能够处理大量的消息。
- 分布式：支持横向扩展。
- 持久性：消息会被持久化到磁盘。
- 灵活性：支持多种消费模式。

---

### 2. 核心概念

#### 2.1 Topic
- **Topic 是消息的分类单元**。
- 每个消息会被发布到某个 Topic 中，消费者订阅相应的 Topic 获取消息。
- Topic 可以细分为多个 **分区（Partition）**。

#### 2.2 Partition
- 每个 Topic 被划分为若干分区，用于提高并行处理能力。
- 分区内的消息有顺序，但跨分区不保证顺序。
- 每个分区中的消息以 **Offset** 标识其在分区内的唯一位置。

#### 2.3 Producer
- **生产者**负责向 Kafka 的 Topic 发布消息。
- 可以通过 Key 指定消息的目标分区。

#### 2.4 Consumer
- **消费者**从 Kafka 的 Topic 中消费消息。
- 消费者可以分组（Consumer Group），同一组中的消费者共同消费一个 Topic 的分区。

#### 2.5 Consumer Group
- 消费者分组实现消息的并行消费。
- **一个分区只能被同一消费组内的一个消费者消费**。
- 不同消费组之间互不影响，可以重复消费消息。

#### 2.6 Broker
- **Kafka Broker** 是 Kafka 集群中的一个节点。
- 每个 Broker 负责存储部分分区的数据。

#### 2.7 Zookeeper
- Kafka 依赖 Zookeeper 进行分布式协调（如选举分区 Leader）。
- 新版本 Kafka 逐步采用 KRaft 协议以替代 Zookeeper。

---

### 3. 工作原理

#### 3.1 消息存储
- 消息以分区为单位存储。
- 消息是持久化存储的，直到超过设置的保留时间。

#### 3.2 消费机制
- Kafka 的消息消费是**拉取模式**。
- 消费者通过维护 Offset 决定从哪里读取消息。
  - **自动提交 Offset**：消费后立即提交进度。
  - **手动提交 Offset**：由消费者显式提交消费进度。

#### 3.3 分区分配
Kafka 的分区分配策略：
- **Range 分配策略**：按分区范围分配给消费者。
- **RoundRobin 分配策略**：轮询分配分区。

---

### 4. 特点和优点
- **高可用性**：Kafka 使用复制机制确保分区的高可用。
- **横向扩展**：通过增加分区或 Broker 提高处理能力。
- **多消费模式**：支持发布/订阅和队列模式。

---

### 5. 基本操作

### 5.1 创建 Topic
```bash
kafka-topics.sh --create --topic <topic-name> --bootstrap-server <broker-list> --partitions <num> --replication-factor <num>
```

#### 5.2 查看 Topic
```bash
kafka-topics.sh --list --bootstrap-server <broker-list>
```

#### 5.3 向 Topic 发送消息
```bash
kafka-console-producer.sh --topic <topic-name> --bootstrap-server <broker-list>
```

#### 5.4 从 Topic 消费消息
```bash
kafka-console-consumer.sh --topic <topic-name> --bootstrap-server <broker-list> --from-beginning
```

---

### 6. 注意事项
- 每个分区只能被同一消费组中的一个消费者消费。
- 一个分区的消息顺序只在分区内保证。
- 消费组之间是互相独立的，允许重复消费。
- 适当设置分区数和消费组内消费者数，避免消费者闲置或分区消费能力不足。

---

### 7. 常见应用场景
- **实时数据流处理**：处理网站点击流或日志。
- **消息队列**：在分布式系统中解耦生产者和消费者。
- **日志收集**：集中化管理和分析日志。
- **事件驱动架构**：触发事件并传递到其他服务。

---

### 8. 新特性：KRaft
- Kafka 新版本（2.8+）逐步替代 Zookeeper，使用 KRaft 协议：
  - 简化架构。
  - 更高的性能和可靠性。

---

## 在 `go` 中使用 `kafka`

目前在 `go` 中使用 `kafka` 的库有：
- [sarama](https://github.com/Shopify/sarama)：一个用于 `Kafka` 的 `Go` 客户端库，当前使用最广泛的 `Kafka Go` 客户端，但随着它的活跃度下降，很多项目开始选择 **kafka-go** 或 **Confluent Kafka Go**。
- [confluent-kafka-go](https://github.com/confluentinc/confluent-kafka-go)：由 Confluent 提供的 `Kafka` 客户端库，依赖本地安装 librdkafka，需要额外的配置。
- [go-kafka](https://github.com/segmentio/kafka-go)：由 Segment 提供的 `Kafka` 客户端库，简单易用且不依赖外部库。

### `sarama`

#### `sarama tools`

`tools` 包提供了一些常用的工具，方便在终端检查生产消息或消费消息的情况。

安装工具:

```bash
go install github.com/Shopify/sarama/tools/kafka-console-consumer@latest
go install github.com/Shopify/sarama/tools/kafka-console-producer@latest
```

使用：

```bash
# 发送一个 "hello world" 消息到 "test" 主题
kafka-console-producer -brokers=localhost:9092 -topic=test -value="hello world"
# 从 "test" 主题消费消息
kafka-console-consumer -brokers=localhost:9092 -topic=test
```

#### 实现生产者

```go
package sarama

import (
	"fmt"
	"github.com/IBM/sarama"
	"github.com/stretchr/testify/assert"
	"testing"
	"time"
)

var (
	Addr      = []string{"localhost:9094"}
	TopicName = "test_topic"
)

func TestSarama_SyncProducer(t *testing.T) {
	cfg := sarama.NewConfig()
	cfg.Producer.Return.Successes = true
	producer, err := sarama.NewSyncProducer(Addr, cfg)
	cfg.Producer.Partitioner = sarama.NewRoundRobinPartitioner
	assert.NoError(t, err)
	defer producer.Close()
	for i := 0; i < 10; i++ {
		msg := &sarama.ProducerMessage{
			Topic: TopicName,
			Value: sarama.StringEncoder(fmt.Sprintf("这是第%d条消息", i+1)),
		}
		_, _, err = producer.SendMessage(msg)
		assert.NoError(t, err)
	}
}

func TestSarama_AsyncProducer(t *testing.T) {
	cfg := sarama.NewConfig()
	cfg.Producer.Return.Successes = true
	cfg.Producer.Return.Errors = true
	cfg.Producer.Partitioner = sarama.NewRoundRobinPartitioner
	producer, err := sarama.NewAsyncProducer(Addr, cfg)
	assert.NoError(t, err)
	defer producer.Close()
	for i := 0; i < 10; i++ {
		msg := &sarama.ProducerMessage{
			Topic: TopicName,
			Value: sarama.StringEncoder(fmt.Sprintf("这是异步消息，第%d条", i+1)),
		}
		producer.Input() <- msg
	}

	for {
		select {
		case err := <-producer.Errors():
			fmt.Println(err)
		case msg := <-producer.Successes():
			fmt.Println(msg.Topic, msg.Value)
		case <-time.After(time.Second * 5):
			return
		}
	}

}

```

#### 实现消费者

```go
package sarama

import (
	"context"
	"github.com/IBM/sarama"
	"github.com/stretchr/testify/assert"
	"log"
	"testing"
	"time"
)

type consumerHandler struct{}

func (c consumerHandler) Setup(session sarama.ConsumerGroupSession) error {
	return nil
}

func (c consumerHandler) Cleanup(session sarama.ConsumerGroupSession) error {
	return nil
}

// batch consume
func (c consumerHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	batchSize := 10
	msgs := claim.Messages()
	for {
		log.Println("start a new round")
		batch := make([]*sarama.ConsumerMessage, 0, batchSize)
		done := false
		ctx, cancel := context.WithTimeout(context.Background(), time.Minute*10)
		for i := 0; i < batchSize && !done; i++ {
			select {
			case <-ctx.Done():
				done = true
			case msg, ok := <-msgs:
				if !ok {
					cancel()
					return nil
				}
				batch = append(batch, msg)
			}
		}
		cancel()
		for _, msg := range batch {
			log.Println(string(msg.Value))
			session.MarkMessage(msg, "")
		}
	}
	return nil
}

// ConsumeClaimV1 single consume
func (c consumerHandler) ConsumeClaimV1(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	msgs := claim.Messages()
	for msg := range msgs {
		log.Println(string(msg.Value))
		session.MarkMessage(msg, "")
	}
	return nil
}

func TestSarama_Consumer(t *testing.T) {
	config := sarama.NewConfig()
	cg, err := sarama.NewConsumerGroup(Addr, "demo", config)
	assert.NoError(t, err)
	defer cg.Close()

	err = cg.Consume(context.Background(), []string{TopicName}, consumerHandler{})
	assert.NoError(t, err)
	select {}
}

```
